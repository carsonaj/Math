
\documentclass[12pt]{amsart}
 \usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb,amsfonts,setspace}

\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{conj}{Conjecture}
\newtheorem{defn}[thm]{Definition}
\newtheorem{note}[thm]{Note}
\newtheorem{ex}[thm]{Exercise}


\newcommand{\al}{\alpha}
\newcommand{\be}{\beta} 
\newcommand{\del}{\delta} 
\newcommand{\Del}{\Delta}
\newcommand{\lam}{\lambda}  
\newcommand{\Lam}{\Lambda} 
\newcommand{\ep}{\epsilon}
\newcommand{\sig}{\sigma} 
\newcommand{\om}{\omega}
\newcommand{\Om}{\Omega}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\MA}{\mathcal{A}}
\newcommand{\MB}{\mathcal{B}}
\newcommand{\MF}{\mathcal{F}}
\newcommand{\MG}{\mathcal{G}}
\newcommand{\ML}{\mathcal{L}}
\newcommand{\MN}{\mathcal{N}}
\newcommand{\MS}{\mathcal{S}}
\newcommand{\MP}{\mathcal{P}}
\newcommand{\ME}{\mathcal{E}}
\newcommand{\MT}{\mathcal{T}}
\newcommand{\MM}{\mathcal{M}}

\newcommand{\RG}{[0,\infty]}
\newcommand{\Rg}{[0,\infty)}
\newcommand{\limfn}{\liminf \limits_{n \rightarrow \infty}}
\newcommand{\limpn}{\limsup \limits_{n \rightarrow \infty}}
\newcommand{\limn}{\lim \limits_{n \rightarrow \infty}}
\newcommand{\convt}[1]{\xrightarrow{\text{#1}}}
\newcommand{\conv}[1]{\xrightarrow{#1}} 

 
 
 
\newcommand\Item[1][]{%
  \ifx\relax#1\relax  \item \else \item[#1] \fi
  \abovedisplayskip=0pt\abovedisplayshortskip=0pt~\vspace*{-\baselineskip}} 
 
 
 
 
 
\begin{document}

\title{Portfolio Theory Notes}
\maketitle

\tableofcontents

\begin{note}
In these notes we will mostly consider random variables $X$ that model returns. As such we may assume that $X \in L^1(\P)$ and $F_X:\R \rightarrow (0,1)$ is bijective and continuous. We will call such random variables "nice". The random variable $X$ will usually refer to the return on some portfolio. As such, we will define the loss of $X$ to be $L_X = -X$.
\end{note}

\section{Risk Measures}

\subsection{Value at Risk}

\begin{defn}
Let $X$ be a nice random variable and $\al \in (0,1)$. We define the \textbf{value at risk of } $X$ \textbf{at confidence level } $\al$, denoted by $VaR_{\al}(X)$, to be 

\begin{align*}
VaR_{\al}(X) 
&= F^{-1}_{-X}(\al)\\
&= F^{-1}_{L_X}(\al)
\end{align*}
Thus $$\P(L_X > VaR_{\al}(X)) = 1- \al$$
\end{defn}

\begin{note}
In practice, we take $\al= .95$ or $\al= .99$. 
\end{note}

\subsection{Estimating the Value at Risk}

\subsection{Average Value at Risk}

 \begin{defn}
Let $X$ be a nice random variable and $\al\in (0,1)$. We define the \textbf{average value at risk of } $X$ \textbf{with tail probability } $\al$, denoted by $AVaR_{\al}(X)$, to be $$AVaR_{\al}(X) = \frac{1}{1-\al}\int_{[\al,1)}VaR_p(X)dm(p)$$
\end{defn}

\begin{note}
If $X$ represents the return on a portfolio, then $AVaR_{\al}(X)$ is just the average of the $VaR_{p}(X)$ on the interval $(\al, 1]$.
\end{note}

\begin{ex}
Let $X$ be a nice random variable and $\al\in (0,1)$. Then 
\begin{align*}
AVaR_{\al}(X) 
&= \E[L_X|L_X \geq Var_{\al}(X)]
\end{align*}
\end{ex}

\begin{proof}
Recall that for measurable spaces $(X,\MA)$ and $(Y, \MB)$, a measurable function $f:X \rightarrow Y$ and a measure $\mu:\MA \rightarrow \RG$, we may form the push-foreward measure of $\mu$ by $f$, $f_{*}\mu:\MB \rightarrow \RG$ with the following property: for each $g:Y \rightarrow \C$, $g \in L^1(f_* \mu)$ iff  $g \circ f \in L^1(\mu)$ and for each $B \in \MB$, 

$$\int_{f^{-1}(B)}g \circ f d\mu = \int_B g d f_*\mu$$

Also recall that for an increasing continuous, bijective $F:\R \rightarrow (0,1)$, we may form the Borel measure $\mu_F$ with $\mu_F((a,b]) = F(b)-F(a)$. Then observe that $F_*\mu_F = m$ because
\begin{align*}
{F}_{*} \mu_F ((a,b]) 
&= \mu_F(F^{-1}((a,b]))\\
&= \mu_F((F^{-1}(a), F^{-1}(b)]) \\ 
&= F(F^{-1}(a)) - F(F^{-1}(b))\\
&= b-a
\end{align*}

Then  
\begin{align*}
\E[L_X |L_X \geq VaR_{\al}(X)]
&= \E[L_X|L_X \geq F^{-1}_{L_X}(\al)] \\ 
&= \frac{1}{1-\al}\E [L_X \mathbf{1}_{\{L_X \geq F^{-1}_{L_X}(\al)\}}] \\ 
&=  \frac{1}{1-\al} \int_{\{L_X \geq F_{L_X}^{-1}(\al)\}}L_X dP \\
& = \frac{1}{1-\al} \int_{[F_{L_X}^{-1}(\al),  \infty)}xd F_{L_X}(x)
\end{align*}

Using the facts recalled earilier, we have  
\begin{align*}
\int_{[F_{L_X}^{-1}(\al),  \infty)}xd F_{L_X}(x) 
&= \int_{[F_{L_X}^{-1}(\al),  \infty)}(F^{-1}_{L_X} \circ F_{L_X}) (x)d F_{L_X}(x) \\
&= \int_{[\al,  1)} F^{-1}_{L_X}(x)dm(x)\\
&= \int_{[\al,  1)} VaR_{\al}(X)dm(x)
\end{align*}
\end{proof}

\begin{lem}
Let $\al \in (0,1)$. Define $f_{\al}: \R \rightarrow \R$ by $$f_\al(\theta) = \theta + \frac{1}{1-\al}\E[(L_X - \theta)^+]$$
Then $f_\al$ is convex and $$\frac{df_\al}{d \theta}(\theta) = \frac{F_{L_X} - \al}{1-\al}$$
\end{lem}

\begin{proof} 
Recall that given $g:\Om \times \R \rightarrow \R$, if for each $\om \in \Om$, $g(\om, \theta)$ is convex in $\theta$, then $\E[g(\cdot, \theta)]$ is convex in theta. For $\om \in \Om, \theta \in \R$, put $$g(\om, \theta) = (L_X(\om) - \theta)^+$$ So $$f_{\al}(\theta) = \theta + \frac{1}{1-\al}\E[g(\theta)]$$ Then for each $\om \in \Om$, $g(\om, \cdot)$ is convex. This implies that for each $\al\in (0,1)$, $f_{\al}$ is convex and therefore continuous. \vspace{3mm}\\ 
Now Let $\theta, \theta' \in \R$. Suppose that $\theta<\theta'$. Then 
\begin{align*}
\frac{f_\al(\theta') - f_\al(\theta)}{\theta' - \theta} 
&= 1 + \frac{1}{1-\al}\E\bigg[\frac{(L_X - \theta')^+ - (L_X - \theta)^+}{\theta'-\theta}\bigg] \\
\end{align*}
For $\om \in \Om$, we have that 
$$\frac{(L_X(\om) - \theta')^+ - (L_X(\om) - \theta)^+}{\theta'-\theta}= 
\begin{cases}
-1 &  \theta' \leq L_X(\om) \\
0 & L_X(\om) \leq  \theta \\
\ep \in (-1,0) &\theta < L_X(\om) < \theta'
\end{cases}$$
This implies that 
\begin{align*}
-(F_{L_X}(\theta') - F_{L_X}(\theta))
&= -\P(\theta < L_X < \theta') \\
&\leq \E\bigg[ \frac{(L_X - \theta')^+ - (L_X - \theta)^+}{\theta'-\theta} \mathbf{1}_{L_X \in (\theta, \theta')}\bigg] \\
&< 0
\end{align*} 
Thus there exists $c \in (0, 1)$ such that $$\E\bigg[ \frac{(L_X - \theta')^+ - (L_X - \theta)^+}{\theta'-\theta} \mathbf{1}_{L_X \in (\theta, \theta')}\bigg] = -c(F_{L_X}(\theta') - F_{L_X}(\theta))$$\vspace{3mm}\\
In addition, $\P(\theta' \leq L_X(\om)) = 1-F_{L_X}(\theta')$.
Therefore 
\begin{align*}
\E\bigg[ \frac{(L_X - \theta')^+ - (L_X - \theta)^+}{\theta'-\theta} \bigg]
&= -(1-F_{L_X}(\theta')) -c(F_{L_X}(\theta') - F_{L_X}(\theta))
\end{align*}\\
This implies that $$\lim_{\theta' \rightarrow \theta^+}\E\bigg[ \frac{(L_X - \theta')^+ - (L_X - \theta)^+}{\theta'-\theta} \bigg] = F_{L_X}(\theta) -1$$\\
Finally we have that 
\begin{align*}
\lim_{\theta' \rightarrow \theta^+} \frac{f_\al(\theta') - f_\al(\theta)}{\theta' - \theta} 
&= 1 + \frac{1}{1-\al}\lim_{\theta' \rightarrow \theta^+}\E\bigg[ \frac{(L_X - \theta')^+ - (L_X - \theta)^+}{\theta'-\theta} \bigg] \\
&= 1 + \frac{F_{L_X}(\theta) -1}{1-\al}\\
&= \frac{F_{L_X}(\theta) -\al}{1-\al}
\end{align*}
The case is similar for the lefthand limit.

\end{proof}

\begin{thm}
Let $X$ be a nice random variable and $\al\in (0,1)$. Then $$AVaR_{\al}(X) = \min_{\theta \in \R} \bigg(\theta + \frac{1}{1-\al}\E[(L_X - \theta)^+]\bigg)$$
\end{thm}

\begin{proof} 
The previous lemma tells us that $$\frac{d f_{\al}}{d \theta}(\theta) = \frac{F_{L_X}(\theta) -\al}{1-\al} $$ For further details, see \cite{RockUr}. Thus $$\lim_{\theta \rightarrow \infty}\frac{d f_{\al}}{d \theta}(\theta) = 1$$ and $$\lim_{\theta \rightarrow -\infty} \frac{d f_{\al}}{d \theta}(\theta) = - \frac{\al}{1-\al} <0$$
The convexity of $f_{\al}$ implies that there exists $\theta^* \in \R$ such that $f_{\al}(\theta^*) = \inf\limits_{\theta \in \R}f_{\al}(\theta)$
Thus $$\frac{d f_{\al}}{d \theta}(\theta^*) = 0$$
which implies that $$F_{L_X}(\theta^*) = \al$$
By definition, $\theta^* = VaR_{\al}(X)$. Finally, evaluating $f_{\al}$ at $\theta^*$ shows us that 

\begin{align*}
f_{\al}(\theta^*)  
&=  \theta^* + \frac{1}{1- \al}\E[(L_X - \theta^*)^+]\\
& = \theta^* + \frac{1}{\P(L_X>\theta^*)}\E[(L_X-\theta^*)\mathbf{1}_{\{L_X>\theta^*\}}] \\
& = \theta^* + \frac{1}{\P(L_X>\theta^*)}\E[L_X\mathbf{1}_{\{L_X>\theta^*\}}] - \frac{1}{\P(L_X>\theta^*)}\E[\theta^*\mathbf{1}_{\{L_X>\theta^*\}}] \\
& = \theta^* + \frac{1}{\P(L_X>\theta^*)}\E[L_X\mathbf{1}_{\{L_X>\theta^*\}}] - \theta^* \\
&= \E[L_X|L_X> \theta^*] \\
& = \E[L_X|L_X>VaR_{\al}(X)] \\
& = AVaR_{\al}(X)
\end{align*}

\end{proof}

\subsection{Estimating the Value at Risk}

\begin{defn}
Let $X$ be a random nice random variable, $X_1, \cdots , X_n \stackrel{iid}{\sim} X$ and $\al\in (0,1)$. Define $$\widehat{VaR_\al}(X) = $$
\end{defn}

\subsection{Estimating the Average Value at Risk}

\begin{defn}
Let $X$ be a random nice random variable, $X_1, \cdots , X_n \stackrel{iid}{\sim} X$ and $\al\in (0,1)$. Define $$ \widehat{AVaR_{\al}(X)} = $$ 
\end{defn}

\begin{lem}
Let $X$ be a random nice random variable, $X_1, \cdots , X_n \stackrel{iid}{\sim} X$ and $\al\in (0,1)$. Then $\widehat{AVarR_{\al}(X)}$ is an unbiased estimator for $AVaR_{\al}(X)$. 
\end{lem}

\begin{proof}
For each $\al\in (0,1), \om \in \Om$ and $\theta \in \R$, define $$f_{\al}(\om)(\theta) = \theta + \frac{1}{n (1-\al)} \sum_{i=1}^n\max(-X_i(\om) - \theta, 0) $$ 

Note that for each $\al\in (0,1)$ and $\om \in \Om$, $f_{\al}(\om)$ is convex and continuous. In this case with no expectation, it is easy to show that $$\lim_{\theta \rightarrow \infty}\frac{\partial f_{\al}(\om)}{\partial \theta}(\theta) = 1$$

and
 
$$\lim_{\theta \rightarrow -\infty}\frac{\partial f_{\al}(\om)}{\partial \theta}(\theta) = -\frac{\al}{1-\al} <0$$  

So for each $\al\in (0,1)$ and $\om \in \Om$, $f_{\al}(\om)$ achieves its minimum at . Then $\{\theta \in \R: f_{\al}(\om)(\theta)\leq m+1\}$ is bounded

Since $f_{\al}$ is continuous, we have that $$\inf_{\theta \in \R} f_{\al}(\theta) = \inf_{\theta \in \Q} f_{\al}(\theta)$$ 

which is measurable. 

\end{proof} 

\bibliographystyle{amsplain}
\bibliography{Portfolio_Theory_References}

\end{document}